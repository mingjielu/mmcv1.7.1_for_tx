// !!! This is a file automatically generated by hipify!!!
#include "hip/hip_runtime.h"
// Copyright (c) OpenMMLab. All rights reserved
#include "pytorch_hip_helper.hpp"
#include "../hip/riroi_align_rotated_hip_kernel.cuh"

void RiROIAlignRotatedForwardCUDAKernelLauncher(
    const at::Tensor features, const at::Tensor rois, const float spatial_scale,
    const int num_samples, const bool clockwise, const int channels,
    const int height, const int width, const int num_rois,
    const int pooled_height, const int pooled_width, const int num_orientations,
    at::Tensor output) {
  const int output_size =
      num_rois * pooled_height * pooled_width * channels * num_orientations;
  at::hip::HIPGuardMasqueradingAsCUDA device_guard(features.device());
  hipStream_t stream = at::hip::getCurrentHIPStreamMasqueradingAsCUDA();
  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
      features.scalar_type(), "riroi_align_rotated_forward_cuda_kernel", ([&] {
        const scalar_t *bottom_data = features.data_ptr<scalar_t>();
        const scalar_t *rois_data = rois.data_ptr<scalar_t>();
        scalar_t *top_data = output.data_ptr<scalar_t>();

       hipLaunchKernelGGL(( riroi_align_rotated_forward_cuda_kernel<scalar_t>)
            , dim3(GET_BLOCKS(output_size)), dim3(THREADS_PER_BLOCK), 0, stream, 
                output_size, bottom_data, rois_data, scalar_t(spatial_scale),
                num_samples, clockwise, channels, height, width, pooled_height,
                pooled_width, num_orientations, top_data);
      }));

  AT_CUDA_CHECK(hipGetLastError());
}

void RiROIAlignRotatedBackwardCUDAKernelLauncher(
    const at::Tensor top_grad, const at::Tensor rois, const float spatial_scale,
    const int num_samples, const bool clockwise, const int channels,
    const int height, const int width, const int num_rois,
    const int pooled_height, const int pooled_width, const int num_orientations,
    at::Tensor bottom_grad) {
  const int output_size =
      num_rois * pooled_height * pooled_width * channels * num_orientations;
  at::hip::HIPGuardMasqueradingAsCUDA device_guard(top_grad.device());
  hipStream_t stream = at::hip::getCurrentHIPStreamMasqueradingAsCUDA();
  AT_DISPATCH_FLOATING_TYPES_AND_HALF(
      top_grad.scalar_type(), "riroi_align_rotated_backward_cuda_kernel", ([&] {
        const scalar_t *top_diff = top_grad.data_ptr<scalar_t>();
        const scalar_t *rois_data = rois.data_ptr<scalar_t>();
        scalar_t *bottom_diff = bottom_grad.data_ptr<scalar_t>();
       hipLaunchKernelGGL(( riroi_align_rotated_backward_cuda_kernel<scalar_t>)
            , dim3(GET_BLOCKS(output_size)), dim3(THREADS_PER_BLOCK), 0, stream, 
                output_size, top_diff, rois_data, spatial_scale, num_samples,
                clockwise, channels, height, width, pooled_height, pooled_width,
                num_orientations, bottom_diff);
      }));
  AT_CUDA_CHECK(hipGetLastError());
}
